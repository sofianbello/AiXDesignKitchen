{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VII_PifuHD.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1Bf4ZBVEkrNztbCGxGSpXCocO6mH3X4p_","authorship_tag":"ABX9TyPd24DuOqRCHX5aRejCa/6m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"VPAnOW_Wm-Qp"},"source":["#@title ## Setup Environment { display-mode: \"form\" }\n","#@markdown This line will install **pytorch3d**.\n","!pip install pytorch3d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AyTSl5POnGzJ"},"source":["#@title Mount Drive { display-mode: \"form\" }\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvGk6gRinJNh"},"source":["#@title  Clone repositories { display-mode: \"form\" }\n","#@markdown Paste the **path** to your working directory below:\n","\n","#@markdown (*The path **must** end with **/** for the code to work properly.*)\n","\n","\n","path = '/content/drive/MyDrive/AiXDesignKitchen/Workshop/' #@param {type:'string'}\n","%cd {path}\n","print('Navigating to Workdirectory...')\n","print('Creating \"PifuHD\"')\n","!mkdir PifuHD\n","print('Open PifuHD...')\n","%cd {path}'PifuHD/'\n","print('Cloning PifuHD...')\n","!git clone https://github.com/facebookresearch/pifuhd\n","print('Cloning lightweight-human-pose-estimation...')\n","!git clone https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch.git\n","print('All done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rp84dPoMnZNn"},"source":["#@title ## Upload Image { display-mode: \"form\" }\n","#@markdown  Run this cell to **upload your image**. Currently PNG, JPEG files are supported. \n","\n","%cd {path}'PifuHD/pifuhd/'\n","!mkdir images\n","%cd {path}'PifuHD/pifuhd/images'\n","from google.colab import files\n","filename = list(files.upload().keys())[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qAmshI8An313"},"source":["#@title Set input and output paths { display-mode: \"form\"}\n","import os\n","\n","try:\n","  image_path = path +'PifuHD/pifuhd/images/%s' % filename\n","except:\n","  image_path = path +'PifuHD/pifuhd/sample_images/test.png' # example image\n","image_dir = os.path.dirname(image_path)\n","file_name = os.path.splitext(os.path.basename(image_path))[0]\n","\n","# output pathes\n","obj_path = path +'PifuHD/pifuhd/results/pifuhd_final/recon/result_%s_256.obj' % file_name\n","out_img_path = path +'PifuHD/pifuhd/results/pifuhd_final/recon/result_%s_256.png' % file_name\n","video_path = path +'PifuHD/pifuhd/results/pifuhd_final/recon/result_%s_256.mp4' % file_name\n","video_display_path = path +'PifuHD/pifuhd/results/pifuhd_final/result_%s_256_display.mp4' % file_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDko-tJkn7-6"},"source":["#@title Load pretrained pose estimation model {display-mode: \"form\"}\n","%cd {path}'PifuHD/lightweight-human-pose-estimation.pytorch/'\n","!wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLJcWqFWoGMg"},"source":["#@title Run PoseEstimation {display-mode: \"form\"}\n","#@markdown In this cell the image gets optimized and then the pose is estimated. Note that it only partially works if the legs are missing.\n","\n","import torch\n","import cv2\n","import numpy as np\n","from models.with_mobilenet import PoseEstimationWithMobileNet\n","from modules.keypoints import extract_keypoints, group_keypoints\n","from modules.load_state import load_state\n","from modules.pose import Pose, track_poses\n","import demo\n","\n","#-----Configurations Start ----# \n","\n","##Only Change these if you know what you are doing!\n","\n","def get_rect(net, images, height_size):\n","    net = net.eval()\n","\n","    stride = 8\n","    upsample_ratio = 4\n","    num_keypoints = Pose.num_kpts\n","    previous_poses = []\n","    delay = 33\n","    for image in images:\n","        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n","        img = cv2.imread(image, cv2.IMREAD_COLOR)\n","        orig_img = img.copy()\n","        orig_img = img.copy()\n","        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n","\n","        total_keypoints_num = 0\n","        all_keypoints_by_type = []\n","        for kpt_idx in range(num_keypoints):  # 19th for bg\n","            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n","\n","        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n","        for kpt_id in range(all_keypoints.shape[0]):\n","            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n","            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n","        current_poses = []\n","\n","        rects = []\n","        for n in range(len(pose_entries)):\n","            if len(pose_entries[n]) == 0:\n","                continue\n","            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n","            valid_keypoints = []\n","            for kpt_id in range(num_keypoints):\n","                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n","                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n","                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n","                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n","            valid_keypoints = np.array(valid_keypoints)\n","            \n","            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n","              pmin = valid_keypoints.min(0)\n","              pmax = valid_keypoints.max(0)\n","\n","              center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int)\n","              radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n","            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n","              # if leg is missing, use pelvis to get cropping\n","              center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int)\n","              radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n","              center[1] += int(0.05*radius)\n","            else:\n","              center = np.array([img.shape[1]//2,img.shape[0]//2])\n","              radius = max(img.shape[1]//2,img.shape[0]//2)\n","\n","            x1 = center[0] - radius\n","            y1 = center[1] - radius\n","\n","            rects.append([x1, y1, 2*radius, 2*radius])\n","\n","        np.savetxt(rect_path, np.array(rects), fmt='%d')\n","\n","#-----Configurations End ----#\n","\n","\n","net = PoseEstimationWithMobileNet()\n","checkpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\n","load_state(net, checkpoint)\n","\n","get_rect(net.cuda(), [image_path], 512)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hu0FYVMpoNJ4"},"source":["#@title Convert to 3D Model {display-mode: \"form\"}\n","print('Downloading pretrained model...')\n","print(' ')\n","\n","%cd {path}'PifuHD/pifuhd/'\n","!sh ./scripts/download_trained_model.sh\n","print(' ')\n","print('Download Completed.')\n","print(' ')\n","print('Converting Image to 3D-Obj...')\n","# Warning: all images with the corresponding rectangle files under -i will be processed. \n","!python -m apps.simple_test -r 256 --use_rect -i $image_dir\n","print(' ')\n","print('All done!')\n","print(' ')\n","print('You can find your results here:')\n","print(obj_path)\n","\n","# seems that 256 is the maximum resolution that can fit into Google Colab. \n","# If you want to reconstruct a higher-resolution mesh, please try with your own machine. "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6JrKoFZXcCmn"},"source":["<i>This tutorial was created by:</i> <br><br><b> Bello / aiXdesign</b> <br>\n","<a href=\"https://aixdesign.space\">aiXdesign</a> \n","<a href=\"http://sofianbello.com\">Web</a> \n","<a href=\"mailto:safian.bello@haw-hamburg.de\">Mail</a><br>\n","<a href=\"https://github.com/sofianbello\">GitHub</a> \n","<a href=\"https://www.linkedin.com/in/sofian-bello-71148a218/\">LinkedIn</a> <br><br>\n","Feel free to get in touch!<br>"]}]}